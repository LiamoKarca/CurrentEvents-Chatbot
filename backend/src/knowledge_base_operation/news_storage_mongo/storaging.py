"""
â€¢ å¾ã€Œåˆä½µåŸæª”ã€åŒ¯å…¥åˆ° MongoDB: News.Real_News
â€¢ _id = {publisher}_{hash16(title|date|url|publisher)}_{YYYY-MM-DD}
  - é›œæ¹Šä¾†æºå«ï¼špublisher, title, date, urlï¼ˆé™ä½æ’åº«ï¼‰
  - é›œæ¹Šé•·åº¦ï¼š16 hexï¼ˆblake2b digest_size=8ï¼‰
â€¢ å¿…å¡«æ¬„ä½ä¸å¯ç‚ºç©ºæˆ–ç©ºç™½ï¼ˆurl/date/publisher/category/title/contentï¼‰
â€¢ åˆ†é–‹çµ±è¨ˆï¼š
  - dup_in_batchï¼šåŒä¸€æ‰¹ä¾†æºå…§çš„é‡è¦†ï¼ˆå…ˆæ“‹ï¼‰
  - dup_in_db   ï¼šè³‡æ–™åº«å·²å­˜åœ¨çš„é‡è¦†ï¼ˆDuplicateKey æˆ–é æŸ¥å‘½ä¸­ï¼‰
  - invalid     ï¼šæ¬„ä½ç©ºç™½/ç¼ºæ¼
â€¢ æ”¯æ´ --dry-runï¼šåªåšçµ±è¨ˆä¸å¯«å…¥
"""

from __future__ import annotations

import argparse
import hashlib
import json
import os
import re
from pathlib import Path
from typing import Any, Dict, Iterable, List, Tuple

from dotenv import load_dotenv
from pymongo import MongoClient, errors

load_dotenv()

# === å¿…å¡«æ¬„ä½ ===
REQUIRED_FIELDS: tuple[str, ...] = (
    "url", "date", "publisher", "category", "title", "content")
INCLUDE_LABEL_IN_REQUIRED = False  # å¦‚éœ€æŠŠ label ä¹Ÿåˆ—ç‚ºå¿…å¡«ï¼Œæ”¹ True

# === ä¾†æºæª”ï¼ˆåˆä½µåŸæª”ï¼‰ ===
RAW_PATH = r"data\processed\news_merge\cna_ey_moi_pts.json"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å·¥å…·å‡½å¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _normalize_windows_like_path(raw: str) -> Path:
    return Path(*raw.split("\\")).resolve()


def _iter_source_paths(src: Path) -> Iterable[Path]:
    if src.is_dir():
        yield from sorted(p for p in src.glob("*.json") if p.is_file())
    elif src.is_file():
        yield src
    else:
        raise FileNotFoundError(f"è®€å–ä¸åˆ° {src}ï¼Œè«‹æª¢æŸ¥è·¯å¾‘ï¼")


def _load_news_items(path: Path) -> List[Dict[str, Any]]:
    with path.open(encoding="utf-8-sig") as f:
        data = json.load(f)
    if isinstance(data, dict):
        return [data]
    if isinstance(data, list):
        return data
    raise ValueError(f"JSON å…§å®¹æ ¼å¼é dict/listï¼š{path}")


def _require_mongo_client() -> MongoClient:
    mongo_uri: str | None = os.getenv("MONGODB_URI")
    if not mongo_uri:
        raise RuntimeError("ç’°å¢ƒè®Šæ•¸ MONGODB_URI æœªè¨­ç½®ï¼Œç„¡æ³•é€£ç·š MongoDBã€‚")
    return MongoClient(mongo_uri)


def _collapse_spaces(s: str) -> str:
    return re.sub(r"\s+", " ", s.strip())


def _hash16(s: str) -> str:
    h = hashlib.blake2b(s.encode("utf-8"), digest_size=8)
    return h.hexdigest()  # 16 hex


def generate_news_id(publisher: str, title: str, date: str, url: str) -> str:
    pub = _collapse_spaces(publisher)
    tit = _collapse_spaces(title)
    dat = _collapse_spaces(date)
    ur = _collapse_spaces(url)
    base = f"{tit}|{dat}|{ur}|{pub}".lower()
    h16 = _hash16(base)
    return f"{pub}_{h16}_{dat}"


def _validate_and_normalize_item(item: Dict[str, Any]) -> Tuple[bool, str]:
    required = list(REQUIRED_FIELDS)
    if INCLUDE_LABEL_IN_REQUIRED:
        required.append("label")
    for key in required:
        if key not in item:
            return False, f"ç¼ºå°‘å¿…å¡«æ¬„ä½ï¼š{key}"
        val = item[key]
        if isinstance(val, str):
            val_norm = _collapse_spaces(val)
            if val_norm == "":
                return False, f"æ¬„ä½ {key} ç‚ºç©ºç™½å­—ä¸²"
            item[key] = val_norm
    # label éå¿…å¡«ï¼Œè‹¥å­˜åœ¨è©¦åšæº«å’Œæ­£è¦åŒ–
    if "label" in item and item["label"] is not None and isinstance(item["label"], str):
        low = item["label"].strip().lower()
        if low in ("true", "1", "yes"):
            item["label"] = True
        elif low in ("false", "0", "no"):
            item["label"] = False
        else:
            item["label"] = _collapse_spaces(item["label"])
    return True, ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åƒæ•¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(
        description="Import merged news JSON into MongoDB News.Real_News with detailed counters.")
    p.add_argument("--src", type=str, default=RAW_PATH,
                   help="JSON æª”è·¯å¾‘æˆ–è³‡æ–™å¤¾ï¼ˆé è¨­ä½¿ç”¨ç¨‹å¼å…§ RAW_PATHï¼‰")
    p.add_argument("--dry-run", action="store_true", help="åªçµ±è¨ˆä¸å¯«å…¥")
    return p.parse_args()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def main() -> None:
    args = parse_args()

    # é€£ç·š
    client = _require_mongo_client()
    db = client["News"]
    coll = db["Real_News"]

    # è¼‰å…¥ä¾†æº
    json_target = _normalize_windows_like_path(args.src)
    src_paths = list(_iter_source_paths(json_target))
    if not src_paths:
        raise FileNotFoundError(f"ä¾†æºä¸­æ²’æœ‰ JSONï¼š{json_target}")

    # å…ˆæŠ“ DB ç¾æœ‰ _idï¼ˆç”¨æ–¼å€åˆ† dup_in_dbï¼‰
    # è‹¥é›†åˆæœªé”æ•¸ç™¾è¬ç´šï¼Œé€™æ¨£åšå¾ˆå®‰å…¨ä¸”å¿«é€Ÿ
    existing_ids = set(doc["_id"] for doc in coll.find({}, {"_id": 1}))
    print(f"ğŸ” DB æ—¢æœ‰å”¯ä¸€ _id æ•¸ï¼š{len(existing_ids)}")

    inserted_total = 0
    dup_in_db_total = 0
    dup_in_batch_total = 0
    invalid_total = 0
    seen_ids_global: set[str] = set()  # ä¹Ÿå¯è·¨æª”å»é‡ï¼ˆä¿å®ˆï¼šé¿å…åŒä¸€æ‰¹å¤šæª”é‡è¦†ï¼‰

    try:
        for file_path in src_paths:
            print(f"â³ è™•ç† {file_path.name} ...")
            news_items = _load_news_items(file_path)

            inserted = 0
            dup_in_db = 0
            dup_in_batch = 0
            invalid = 0

            seen_ids: set[str] = set()  # æª”å…§å»é‡

            for item in news_items:
                ok, reason = _validate_and_normalize_item(item)
                if not ok:
                    invalid += 1
                    continue

                news_id = generate_news_id(
                    publisher=item["publisher"],
                    title=item["title"],
                    date=item["date"],
                    url=item["url"],
                )
                item["_id"] = news_id

                # å…ˆåšæ‰¹å…§å»é‡ï¼ˆæª”å…§ + è·¨æª”ï¼‰
                if news_id in seen_ids or news_id in seen_ids_global:
                    dup_in_batch += 1
                    continue
                seen_ids.add(news_id)
                seen_ids_global.add(news_id)

                # å†åˆ¤æ–· DB æ˜¯å¦å·²æœ‰
                if news_id in existing_ids:
                    dup_in_db += 1
                    continue

                if args.dry_run:
                    # ä¸å¯«å…¥ï¼Œåªçµ±è¨ˆï¼Œè¦–ç‚ºã€Œå¯æ–°å¢ã€
                    inserted += 1
                else:
                    try:
                        coll.insert_one(item)
                        inserted += 1
                        existing_ids.add(news_id)  # å¯«å…¥æˆåŠŸå¾ŒåŒæ­¥æ›´æ–°å¿«å–é›†åˆ
                    except errors.DuplicateKeyError:
                        # å¦‚æœç«¶æ…‹æˆ–å…¶ä»–ç¨‹åºå‰›å¥½æ’å…¥ï¼Œé€™è£¡ä»å¯èƒ½æ’åˆ°
                        dup_in_db += 1

            print(
                f"  âœ… å¯æ–°å¢/å·²æ–°å¢ {inserted}ï¼Œdup_in_db {dup_in_db}ï¼Œdup_in_batch {dup_in_batch}ï¼Œinvalid {invalid}")
            inserted_total += inserted
            dup_in_db_total += dup_in_db
            dup_in_batch_total += dup_in_batch
            invalid_total += invalid

        print("\nğŸ‰ å…¨éƒ¨å®Œæˆ")
        mode = "ï¼ˆä¹¾è·‘ï¼Œä¸å¯«å…¥ï¼‰" if args.dry_run else ""
        print(f"    æ¨¡å¼ï¼š{mode}")
        print(f"    å¯æ–°å¢/å·²æ–°å¢ï¼š{inserted_total}")
        print(f"    dup_in_db    ï¼š{dup_in_db_total}  â† èˆ‡ã€DB å·²æœ‰ã€ç›´æ¥å°æ‡‰")
        print(f"    dup_in_batch ï¼š{dup_in_batch_total}  â† åŒä¸€æ‰¹ä¾†æºæª”å…§é‡è¦†")
        print(f"    invalid      ï¼š{invalid_total}  â† æ¬„ä½ç©ºç™½/ç¼ºæ¼")
        if not args.dry_run:
            # æœ€çµ‚ DB æ•¸é‡ï¼ˆç²¾æº–ï¼‰
            final_count = coll.count_documents({})
            print(f"    æœ€çµ‚ DB ç¸½ç­†æ•¸ï¼ˆcountDocumentsï¼‰ï¼š{final_count}")

    finally:
        client.close()


if __name__ == "__main__":
    main()
